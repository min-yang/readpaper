{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "from pymongo import MongoClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('clm_train.txt') or not os.path.exists('clm_valid.txt'):\n",
    "    limit = 100000\n",
    "    c = MongoClient()\n",
    "    #如果文档数量过多，则需要分批进行训练\n",
    "    docs = list(c.article.crawl.find(projection=['summary'], limit=limit))\n",
    "    random.shuffle(docs)\n",
    "    n_doc = len(docs)\n",
    "    n_train = 1000 #int(0.9 * n_doc)\n",
    "    n_valid = 1100 #n_doc\n",
    "    with open('clm_train.txt', 'w') as fw:\n",
    "        for doc in docs[:n_train]:\n",
    "            fw.write(doc['summary'])\n",
    "            \n",
    "    with open('clm_valid.txt', 'w') as fw:\n",
    "        for doc in docs[n_train:n_valid]:\n",
    "            fw.write(doc['summary'])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-ba418acf56910de3\n",
      "Reusing dataset text (/home/min/.cache/huggingface/datasets/text/default-ba418acf56910de3/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "datasets = load_dataset(\"text\", data_files={\"train\": 'clm_train.txt', \"validation\": 'clm_valid.txt'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"hfl/chinese-xlnet-base\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/min/.cache/huggingface/datasets/text/default-ba418acf56910de3/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5/cache-5ead30a09a33aaa8.arrow\n",
      "Loading cached processed dataset at /home/min/.cache/huggingface/datasets/text/default-ba418acf56910de3/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5/cache-65e70f768df2b145.arrow\n",
      "Loading cached processed dataset at /home/min/.cache/huggingface/datasets/text/default-ba418acf56910de3/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5/cache-1618ffc1edb35c25.arrow\n",
      "Loading cached processed dataset at /home/min/.cache/huggingface/datasets/text/default-ba418acf56910de3/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5/cache-b554fb49e0341706.arrow\n",
      "Loading cached processed dataset at /home/min/.cache/huggingface/datasets/text/default-ba418acf56910de3/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5/cache-3d2c2c70f90605c8.arrow\n",
      "Loading cached processed dataset at /home/min/.cache/huggingface/datasets/text/default-ba418acf56910de3/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5/cache-0190c0ae80a6831b.arrow\n",
      "Loading cached processed dataset at /home/min/.cache/huggingface/datasets/text/default-ba418acf56910de3/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5/cache-f5a5cf11e316764c.arrow\n",
      "Loading cached processed dataset at /home/min/.cache/huggingface/datasets/text/default-ba418acf56910de3/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5/cache-cd9019f24ee429df.arrow\n"
     ]
    }
   ],
   "source": [
    "tokenized_datasets = datasets.map(tokenize_function, batched=True, num_proc=4, remove_columns=[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_texts(examples):\n",
    "    # Concatenate all texts.\n",
    "    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
    "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "    # We drop the small remainder, we could add padding if the model supported it instead of this drop, you can\n",
    "        # customize this part to your needs.\n",
    "    total_length = (total_length // block_size) * block_size\n",
    "    # Split by chunks of max_len.\n",
    "    result = {\n",
    "        k: [t[i : i + block_size] for i in range(0, total_length, block_size)]\n",
    "        for k, t in concatenated_examples.items()\n",
    "    }\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/min/.cache/huggingface/datasets/text/default-ba418acf56910de3/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5/cache-acb1fdeb0e8502a1.arrow\n",
      "Loading cached processed dataset at /home/min/.cache/huggingface/datasets/text/default-ba418acf56910de3/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5/cache-14264015c3e3949d.arrow\n",
      "Loading cached processed dataset at /home/min/.cache/huggingface/datasets/text/default-ba418acf56910de3/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5/cache-3937d3f26488a288.arrow\n",
      "Loading cached processed dataset at /home/min/.cache/huggingface/datasets/text/default-ba418acf56910de3/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5/cache-c19169df58e012be.arrow\n",
      "Loading cached processed dataset at /home/min/.cache/huggingface/datasets/text/default-ba418acf56910de3/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5/cache-c9d0e22b4d2a680f.arrow\n",
      "Loading cached processed dataset at /home/min/.cache/huggingface/datasets/text/default-ba418acf56910de3/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5/cache-7590c52e6fc0df8c.arrow\n",
      "Loading cached processed dataset at /home/min/.cache/huggingface/datasets/text/default-ba418acf56910de3/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5/cache-98e8783dcaf3667e.arrow\n",
      "Loading cached processed dataset at /home/min/.cache/huggingface/datasets/text/default-ba418acf56910de3/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5/cache-94bb80540f7f7f72.arrow\n"
     ]
    }
   ],
   "source": [
    "lm_datasets = tokenized_datasets.map(\n",
    "    group_texts,\n",
    "    batched=True,\n",
    "    batch_size=1000,\n",
    "    num_proc=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'、无人机和828辆消防车参与了灭火工作。<sep><cls>  报道称,土耳其过去8天发生近200起森林野火,其中15起林火未获控制。西南部木拉省一处火场延烧附近火力发电厂边缘,电厂已疏散人员,易燃易爆物也已移除。<sep><cls>  土耳其总统埃尔多安称:“这座火力发电厂可能被烧成平地......要不是风势猛烈,火势早就控制下来。”<sep><cls>  于一周前最早传出大火的南部安塔利亚'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(lm_datasets[\"train\"][1][\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "model = AutoModelForCausalLM.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def textgen():\n",
    "    prefix = '在所有的木偶表演中，提线木偶难度最大。提线木偶是演员自上而下以数十条丝线操纵木偶表演的艺术。演员必须熟练掌握10多种理线技巧和30多种组织提线以表演各个行当、各种动作的“线规”，才有资格走上舞台。'\n",
    "    prompt_text = prefix + '我希望'\n",
    "    encoded_prompt = tokenizer.encode(prompt_text, add_special_tokens=False, return_tensors='pt')\n",
    "    output_sequences = model.generate(\n",
    "        encoded_prompt, \n",
    "        max_length=20+len(encoded_prompt[0]),\n",
    "        temperature=0.1,\n",
    "        top_k=0,\n",
    "        top_p=0.9,\n",
    "        repetition_penalty=1.0,\n",
    "        do_sample=True,\n",
    "    )\n",
    "    print(tokenizer.decode(output_sequences[0], clean_up_tokenization_spaces=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "在所有的木偶表演中,提线木偶难度最大。提线木偶是演员自上而下以数十条丝线操纵木偶表演的艺术。演员必须熟练掌握10多种理线技巧和30多种组织提线以表演各个行当、各种动作的“线规”,才有资格走上舞台。我希望,在我看来,提线木偶是个好演员。 好演员,是个\n"
     ]
    }
   ],
   "source": [
    "textgen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/min/anaconda3/envs/image_detection/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at  /opt/conda/conda-bld/pytorch_1607370117127/work/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    \"test-clm\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=lm_datasets[\"train\"],\n",
    "    eval_dataset=lm_datasets[\"validation\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 8094\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3036\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='22' max='3036' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  22/3036 02:23 < 5:59:33, 0.14 it/s, Epoch 0.02/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "textgen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "image_detection",
   "language": "python",
   "name": "image_detection"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
