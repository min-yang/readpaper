{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import random\n",
    "import json\n",
    "\n",
    "from pymongo import MongoClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('clm_train.txt') or not os.path.exists('clm_valid.txt'):\n",
    "    c = MongoClient()\n",
    "    train_file = open('clm_train.txt', 'w')\n",
    "    test_file = open('clm_valid.txt', 'w')\n",
    "    for doc in c.article.crawl.find(projection=['summary']):\n",
    "        if random.random() < 0.1:\n",
    "            test_file.write(doc['summary'])\n",
    "        train_file.write(doc['summary'])      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-398c787d8b9b2cbf\n",
      "Reusing dataset text (/home/min/.cache/huggingface/datasets/text/default-398c787d8b9b2cbf/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "datasets = load_dataset(\"text\", data_files={\"train\": 'clm_valid.txt', \"validation\": 'clm_valid.txt'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"hfl/chinese-xlnet-base\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets = datasets.map(tokenize_function, batched=True, num_proc=4, remove_columns=[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_texts(examples):\n",
    "    # Concatenate all texts.\n",
    "    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
    "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "    # We drop the small remainder, we could add padding if the model supported it instead of this drop, you can\n",
    "        # customize this part to your needs.\n",
    "    total_length = (total_length // block_size) * block_size\n",
    "    # Split by chunks of max_len.\n",
    "    result = {\n",
    "        k: [t[i : i + block_size] for i in range(0, total_length, block_size)]\n",
    "        for k, t in concatenated_examples.items()\n",
    "    }\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_datasets = tokenized_datasets.map(\n",
    "    group_texts,\n",
    "    batched=True,\n",
    "    batch_size=1000,\n",
    "    num_proc=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'新华社北京8月1日电为全面展现和生动反映以习近平同志为核心的党中央团结带领全党全国各族人民顽强奋斗、如期全面建成小康社会的伟大历程和辉煌成就,由中央宣传部指导、中央广播电视总台承制的5集电视专题片《人民的小康》,将于2日起在中央电视台综合频道黄金时段播出。据介绍,该片分为《一诺千钧》《脱贫攻坚》《民生福祉》《美好生活》《关键一步》等5个篇章,充分展现以习近平同志为核心的党中央'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(lm_datasets[\"train\"][0][\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "model = AutoModelForCausalLM.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def textgen():\n",
    "    prefix = '在所有的木偶表演中，提线木偶难度最大。提线木偶是演员自上而下以数十条丝线操纵木偶表演的艺术。演员必须熟练掌握10多种理线技巧和30多种组织提线以表演各个行当、各种动作的“线规”，才有资格走上舞台。'\n",
    "    prompt_text = prefix + '我希望'\n",
    "    encoded_prompt = tokenizer.encode(prompt_text, add_special_tokens=False, return_tensors='pt')\n",
    "    output_sequences = model.generate(\n",
    "        encoded_prompt, \n",
    "        max_length=20+len(encoded_prompt[0]),\n",
    "        temperature=0.1,\n",
    "        top_k=0,\n",
    "        top_p=0.9,\n",
    "        repetition_penalty=1.0,\n",
    "        do_sample=True,\n",
    "    )\n",
    "    print(tokenizer.decode(output_sequences[0], clean_up_tokenization_spaces=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "在所有的木偶表演中,提线木偶难度最大。提线木偶是演员自上而下以数十条丝线操纵木偶表演的艺术。演员必须熟练掌握10多种理线技巧和30多种组织提线以表演各个行当、各种动作的“线规”,才有资格走上舞台。我希望,在我看来,提线木偶是个好演员。 好演员,是个\n"
     ]
    }
   ],
   "source": [
    "textgen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/min/anaconda3/envs/image_detection/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at  /opt/conda/conda-bld/pytorch_1607370117127/work/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    \"test-clm\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=lm_datasets[\"train\"],\n",
    "    eval_dataset=lm_datasets[\"validation\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 8094\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3036\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='22' max='3036' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  22/3036 02:23 < 5:59:33, 0.14 it/s, Epoch 0.02/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "textgen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'input_ids': [19, 21222, 528, 69, 25, 41, 29, 910, 39, 2681, 14027, 24, 153, 1004, 6147, 37, 17163, 6796, 39, 2756, 20, 654, 432, 10231, 7905, 213, 654, 1040, 291, 584, 744, 22206, 1092, 13987, 2324, 21, 174, 449, 2681, 2907, 96, 548, 1068, 20, 14582, 2710, 976, 24, 6053, 17389, 4425, 17, 53, 432, 16505, 5625, 21, 432, 17917, 682, 200, 1252, 8693, 56, 300, 2671, 20376, 463, 36, 744, 3081, 548, 31, 17, 134, 72, 45, 1947, 23, 19158, 3799, 3530, 7170, 17687, 1224, 18, 4490, 5728, 17, 11607, 2554, 36, 59, 844, 850, 14150, 12294, 4061, 9494, 1944, 3811, 12294, 11675, 512, 23159, 12294, 17040, 896, 12294, 7308, 10888, 31, 54, 56, 249, 1517, 705, 17, 6820, 14027, 37, 17163, 6796, 39, 2756, 20, 654, 432], 'labels': [19, 21222, 528, 69, 25, 41, 29, 910, 39, 2681, 14027, 24, 153, 1004, 6147, 37, 17163, 6796, 39, 2756, 20, 654, 432, 10231, 7905, 213, 654, 1040, 291, 584, 744, 22206, 1092, 13987, 2324, 21, 174, 449, 2681, 2907, 96, 548, 1068, 20, 14582, 2710, 976, 24, 6053, 17389, 4425, 17, 53, 432, 16505, 5625, 21, 432, 17917, 682, 200, 1252, 8693, 56, 300, 2671, 20376, 463, 36, 744, 3081, 548, 31, 17, 134, 72, 45, 1947, 23, 19158, 3799, 3530, 7170, 17687, 1224, 18, 4490, 5728, 17, 11607, 2554, 36, 59, 844, 850, 14150, 12294, 4061, 9494, 1944, 3811, 12294, 11675, 512, 23159, 12294, 17040, 896, 12294, 7308, 10888, 31, 54, 56, 249, 1517, 705, 17, 6820, 14027, 37, 17163, 6796, 39, 2756, 20, 654, 432], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "print(lm_datasets['train'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'input_ids': [19, 21222, 528, 69, 25, 41, 29, 910, 39, 2681, 14027, 24, 153, 1004, 6147, 37, 17163, 6796, 39, 2756, 20, 654, 432, 10231, 7905, 213, 654, 1040, 291, 584, 744, 22206, 1092, 13987, 2324, 21, 174, 449, 2681, 2907, 96, 548, 1068, 20, 14582, 2710, 976, 24, 6053, 17389, 4425, 17, 53, 432, 16505, 5625, 21, 432, 17917, 682, 200, 1252, 8693, 56, 300, 2671, 20376, 463, 36, 744, 3081, 548, 31, 17, 134, 72, 45, 1947, 23, 19158, 3799, 3530, 7170, 17687, 1224, 18, 4490, 5728, 17, 11607, 2554, 36, 59, 844, 850, 14150, 12294, 4061, 9494, 1944, 3811, 12294, 11675, 512, 23159, 12294, 17040, 896, 12294, 7308, 10888, 31, 54, 56, 249, 1517, 705, 17, 6820, 14027, 37, 17163, 6796, 39, 2756, 20, 654, 432, 116, 5171, 1890, 2681, 2907, 96, 548, 1068, 20, 5252, 24640, 1784, 24, 2966, 6370, 17, 213, 270, 209, 11491, 2681, 2907, 96, 548, 1068, 5699, 114, 4425, 17, 18841, 151, 6147, 435, 5575, 20, 7765, 96, 548, 896, 24, 2264, 3317, 2359, 22343, 18, 4490, 6295, 17, 11607, 3191, 6684, 37, 2045, 1611, 2544, 3388, 343, 17, 37, 4965, 316, 2038, 39, 7473, 17, 37, 2082, 1298, 39, 2743, 17, 220, 1319, 8773, 2045, 10532, 153, 1004, 114, 7115, 2994, 18, 9803, 299, 6336, 5809, 1040, 2425, 17, 3390, 9820, 963, 27, 1257, 21, 296, 84, 12212, 17, 6954, 14027, 35, 5324, 12218, 2638, 2681, 96, 548, 2450, 18320, 21, 84, 7725, 18, 4, 3], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2]}\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_datasets['train'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': '\\t新华社北京8月1日电为全面展现和生动反映以习近平同志为核心的党中央团结带领全党全国各族人民顽强奋斗、如期全面建成小康社会的伟大历程和辉煌成就，由中央宣传部指导、中央广播电视总台承制的5集电视专题片《人民的小康》，将于2日起在中央电视台综合频道黄金时段播出。据介绍，该片分为《一诺千钧》《脱贫攻坚》《民生福祉》《美好生活》《关键一步》等5个篇章，充分展现以习近平同志为核心的党中央对决胜全面建成小康社会的战略擘画和重大部署，全方位呈现全面建成小康社会的历史性成就，立体化反映老百姓的幸福小康生活和昂扬精神风貌。据悉，该片创作坚持以思想引领为主线，以具体事例为主体，以普通人物为主角，力求体现思想性和生动性有机统一。摄制团队深入全国各地，拍摄了许多感人故事、清新画面，真实展现了中华大地实现全面小康的新面貌、新气象。'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 4, 3]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode('<sep>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-cb1381deea317b8a\n"
     ]
    }
   ],
   "source": [
    "datasets = load_dataset(\"text\", data_files={\"train\": 'clm_train.txt', \"validation\": 'clm_valid.txt'}, streaming=True)\n",
    "tokenized_datasets = datasets['train'].map(tokenize_function, batched=True)\n",
    "lm_datasets = tokenized_datasets.map(\n",
    "    group_texts,\n",
    "    batched=True,\n",
    "    batch_size=1000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ''}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(datasets['train']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 3]\n"
     ]
    }
   ],
   "source": [
    "print(next(iter(tokenized_datasets))['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 3, 19, 654, 20, 3497, 44, 3377, 17, 2136, 69, 22, 87, 20, 3428, 13987, 2324, 17, 64, 10311, 2542, 17, 159, 174, 449, 600, 84, 2603, 4061, 9494, 1944, 3811, 4132, 2361, 17, 15371, 421, 17124, 18320, 5111, 4167, 17, 8372, 35, 10068, 15371, 18, 8372, 10068, 15371, 657, 17, 7308, 202, 17123, 17799, 12070, 4061, 9494, 1944, 3811, 6712, 203, 12208, 1702, 1106, 2774, 9602, 740, 18177, 258, 17, 908, 4061, 9494, 5161, 2758, 9567, 2012, 21, 18067, 219, 119, 3428, 18, 544, 29, 17, 22695, 1096, 1506, 10372, 198, 1493, 137, 28, 2118, 614, 168, 2662, 7841, 4061, 9494, 1944, 3811, 66, 12208, 1702, 1106, 2774, 9602, 740, 1205, 357, 20376, 1022, 4286, 18, 341, 614, 23, 4311, 4584, 10568, 2177, 220, 76, 17]\n"
     ]
    }
   ],
   "source": [
    "print(next(iter(lm_datasets))['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<sep><cls> 党的十八大以来,经过8年多的持续奋斗,到2020年底,中国如期完成新时代脱贫攻坚目标任务,贫困地区落后面貌根本改变,消除了绝对贫困。消除绝对贫困之后,关键要做好巩固拓展脱贫攻坚成果同乡村振兴有效衔接各项工作,让脱贫基础更加稳固、成效更可持续。近日,课题组赴重庆市石柱县中益乡就如何推进脱贫攻坚与乡村振兴有效衔接问题进行专题调研。该乡在融创中国的助力下,'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(next(iter(lm_datasets))[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'input_ids': [19, 3799, 3466, 17, 10779, 22, 254, 266, 10448, 578, 455, 9594, 2713, 66, 1323, 1836, 2348, 1284, 6535, 12154, 17, 1706, 1084, 2761, 16529, 17, 2720, 455, 3654, 16628, 24, 999, 2078, 6163, 5368, 20, 8770, 18, 9612, 11920, 19694, 1359, 57, 29, 262, 17, 6592, 421, 20359, 578, 455, 1084, 144, 17, 52, 5476, 5794, 5000, 7119, 2758, 14032, 18, 4, 3, 19, 65, 2713, 1218, 14624, 421, 17, 14297, 978, 1753, 596, 9803, 281, 305, 17, 3428, 17753, 1226, 29, 254, 6670, 11454, 627, 15361, 18, 140, 15361, 1299, 3377, 17, 15467, 27, 919, 192, 4577, 15381, 18, 2262, 1187, 120, 1740, 1901, 21, 6709, 21, 3321, 24, 13833, 20, 1869, 6249, 508, 23, 3116, 5440, 455, 18, 12716, 248, 22658, 21, 1054, 993, 13710], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'labels': [19, 3799, 3466, 17, 10779, 22, 254, 266, 10448, 578, 455, 9594, 2713, 66, 1323, 1836, 2348, 1284, 6535, 12154, 17, 1706, 1084, 2761, 16529, 17, 2720, 455, 3654, 16628, 24, 999, 2078, 6163, 5368, 20, 8770, 18, 9612, 11920, 19694, 1359, 57, 29, 262, 17, 6592, 421, 20359, 578, 455, 1084, 144, 17, 52, 5476, 5794, 5000, 7119, 2758, 14032, 18, 4, 3, 19, 65, 2713, 1218, 14624, 421, 17, 14297, 978, 1753, 596, 9803, 281, 305, 17, 3428, 17753, 1226, 29, 254, 6670, 11454, 627, 15361, 18, 140, 15361, 1299, 3377, 17, 15467, 27, 919, 192, 4577, 15381, 18, 2262, 1187, 120, 1740, 1901, 21, 6709, 21, 3321, 24, 13833, 20, 1869, 6249, 508, 23, 3116, 5440, 455, 18, 12716, 248, 22658, 21, 1054, 993, 13710]}\n"
     ]
    }
   ],
   "source": [
    "print(next(iter(lm_datasets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'input_ids': [19, 3799, 3466, 17, 10779, 22, 254, 266, 10448, 578, 455, 9594, 2713, 66, 1323, 1836, 2348, 1284, 6535, 12154, 17, 1706, 1084, 2761, 16529, 17, 2720, 455, 3654, 16628, 24, 999, 2078, 6163, 5368, 20, 8770, 18, 9612, 11920, 19694, 1359, 57, 29, 262, 17, 6592, 421, 20359, 578, 455, 1084, 144, 17, 52, 5476, 5794, 5000, 7119, 2758, 14032, 18, 4, 3, 19, 65, 2713, 1218, 14624, 421, 17, 14297, 978, 1753, 596, 9803, 281, 305, 17, 3428, 17753, 1226, 29, 254, 6670, 11454, 627, 15361, 18, 140, 15361, 1299, 3377, 17, 15467, 27, 919, 192, 4577, 15381, 18, 2262, 1187, 120, 1740, 1901, 21, 6709, 21, 3321, 24, 13833, 20, 1869, 6249, 508, 23, 3116, 5440, 455, 18, 12716, 248, 22658, 21, 1054, 993, 13710], 'labels': [19, 3799, 3466, 17, 10779, 22, 254, 266, 10448, 578, 455, 9594, 2713, 66, 1323, 1836, 2348, 1284, 6535, 12154, 17, 1706, 1084, 2761, 16529, 17, 2720, 455, 3654, 16628, 24, 999, 2078, 6163, 5368, 20, 8770, 18, 9612, 11920, 19694, 1359, 57, 29, 262, 17, 6592, 421, 20359, 578, 455, 1084, 144, 17, 52, 5476, 5794, 5000, 7119, 2758, 14032, 18, 4, 3, 19, 65, 2713, 1218, 14624, 421, 17, 14297, 978, 1753, 596, 9803, 281, 305, 17, 3428, 17753, 1226, 29, 254, 6670, 11454, 627, 15361, 18, 140, 15361, 1299, 3377, 17, 15467, 27, 919, 192, 4577, 15381, 18, 2262, 1187, 120, 1740, 1901, 21, 6709, 21, 3321, 24, 13833, 20, 1869, 6249, 508, 23, 3116, 5440, 455, 18, 12716, 248, 22658, 21, 1054, 993, 13710], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "print(lm_datasets['train'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = iter(lm_datasets)\n",
    "count = 0\n",
    "for data in gen:\n",
    "    count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XLNetLMHeadModel(\n",
       "  (transformer): XLNetModel(\n",
       "    (word_embedding): Embedding(32000, 768)\n",
       "    (layer): ModuleList(\n",
       "      (0): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (1): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (2): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (3): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (4): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (5): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (6): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (7): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (8): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (9): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (10): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (11): XLNetLayer(\n",
       "        (rel_attn): XLNetRelativeAttention(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ff): XLNetFeedForward(\n",
       "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_loss): Linear(in_features=768, out_features=32000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_from_scratch():\n",
    "    vocab_file = 'vocab.json'\n",
    "    train_file = 'clm_train.txt'\n",
    "    \n",
    "    if not os.path.exists(vocab_file):\n",
    "        char_set = set()\n",
    "        for line in open(train_file):\n",
    "            line = re.sub(r'\\s', '', line)\n",
    "            for char in line:\n",
    "                char_set.add(char)\n",
    "        \n",
    "        vocab_dict = {'id2token': {}, 'token2id': {}}\n",
    "        idx = 0\n",
    "        for char in char_set:\n",
    "            vocab_dict['id2token'][idx] = char\n",
    "            vocab_dict['token2id'][char] = idx\n",
    "            idx += 1\n",
    "            \n",
    "        json.dump(vocab_dict, open(vocab_file, 'w'), ensure_ascii=False)\n",
    "    \n",
    "    tokenizer = myTokenizer(vocab_file)\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myTokenizer:\n",
    "    def __init__(self, vocab_file):\n",
    "        vocab_dict = json.load(open(vocab_file))\n",
    "        self.id2token = vocab_dict['id2token']\n",
    "        self.token2id = vocab_dict['token2id']\n",
    "        self.bos_token_id = len(self.id2token) # 对应\\t\n",
    "        self.id2token[self.bos_token_id] = '\\t'\n",
    "        self.token2id['\\t'] = self.bos_token_id\n",
    "    \n",
    "    @property\n",
    "    def size(self):\n",
    "        return len(self.id2token)\n",
    "    \n",
    "    def __call__(self, text):\n",
    "        return self.encode(text)\n",
    "    \n",
    "    def encode(self, text):\n",
    "        data = {'input_ids': [], 'attention_mask': []}\n",
    "        if isinstance(text, str):\n",
    "            for char in text:\n",
    "                token_id = self.token2id.get(char)\n",
    "                if token_id:\n",
    "                    data['input_ids'].append(token_id)\n",
    "                    data['attention_mask'].append(1)\n",
    "        elif isinstance(text, list):\n",
    "            for ele in text:\n",
    "                input_ids = []\n",
    "                attention_mask = []\n",
    "                for char in ele:\n",
    "                    token_id = self.token2id.get(char)\n",
    "                    if token_id:\n",
    "                        input_ids.append(token_id)\n",
    "                        attention_mask.append(1)\n",
    "                data['input_ids'].append(input_ids)\n",
    "                data['attention_mask'].append(attention_mask)\n",
    "        return data\n",
    "    \n",
    "    def decode(self, id_list):\n",
    "        if isinstance(id_list, int):\n",
    "            id_list = [id_list]\n",
    "            \n",
    "        text = ''\n",
    "        for token_id in id_list:\n",
    "            if token_id == self.bos_token_id:\n",
    "                text += '\\t'\n",
    "            else:\n",
    "                token = self.id2token.get(str(token_id))\n",
    "                if token:\n",
    "                    text += token\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = train_from_scratch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[4959, 4959, 3020, 2406, 2758], [5888, 4559]],\n",
       " 'attention_mask': [[1, 1, 1, 1, 1], [1, 1]]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(['看看是什么', '测试'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\t看看是什么'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([6447, 4959, 4959, 3020, 2406, 2758])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6448"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-398c787d8b9b2cbf\n",
      "Reusing dataset text (/home/min/.cache/huggingface/datasets/text/default-398c787d8b9b2cbf/0.0.0/e16f44aa1b321ece1f87b07977cc5d70be93d69b20486d6dacd62e12cf25c9a5)\n"
     ]
    }
   ],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer.encode(examples[\"text\"])\n",
    "\n",
    "datasets = load_dataset(\"text\", data_files={\"train\": 'clm_valid.txt', \"validation\": 'clm_valid.txt'})\n",
    "tokenized_datasets = datasets.map(tokenize_function, batched=True, num_proc=4, remove_columns=[\"text\"])\n",
    "lm_datasets = tokenized_datasets.map(\n",
    "    group_texts,\n",
    "    batched=True,\n",
    "    batch_size=1000,\n",
    "    num_proc=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': '\\t新华社北京8月1日电为全面展现和生动反映以习近平同志为核心的党中央团结带领全党全国各族人民顽强奋斗、如期全面建成小康社会的伟大历程和辉煌成就，由中央宣传部指导、中央广播电视总台承制的5集电视专题片《人民的小康》，将于2日起在中央电视台综合频道黄金时段播出。据介绍，该片分为《一诺千钧》《脱贫攻坚》《民生福祉》《美好生活》《关键一步》等5个篇章，充分展现以习近平同志为核心的党中央对决胜全面建成小康社会的战略擘画和重大部署，全方位呈现全面建成小康社会的历史性成就，立体化反映老百姓的幸福小康生活和昂扬精神风貌。据悉，该片创作坚持以思想引领为主线，以具体事例为主体，以普通人物为主角，力求体现思想性和生动性有机统一。摄制团队深入全国各地，拍摄了许多感人故事、清新画面，真实展现了中华大地实现全面小康的新面貌、新气象。'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'input_ids': [6447, 3004, 3097, 5849, 5453, 3023, 1454, 1992, 2692, 4530, 5481, 2117, 3634, 4328, 1336, 4557, 5734, 373, 538, 1317, 1598, 5095, 3021, 4282, 2339, 4590, 1679, 2117, 4845, 4303, 4250, 2141, 2258, 5748, 5833, 2105, 5384, 6402, 3634, 2141, 3634, 5454, 4771, 5285, 378, 5929, 5482, 2654, 4817, 4844, 4327, 2158, 483, 3634, 4328, 3139, 4228, 2079, 943, 5849, 5303, 4250, 3455, 2935, 1525, 4102, 5734, 5295, 5455, 4228, 1155, 1217, 621, 2258, 5748, 2312, 3251, 5343, 4470, 1068, 4327, 2258, 5748, 5342, 5490, 5481, 115, 6019, 4935, 3532, 5194, 4250, 2811, 5257, 5481, 115, 1927, 314, 1666, 5226, 378, 5929, 4250, 2079, 943, 963, 1217, 5715, 4985, 5098, 4530, 6182, 2173, 2258, 5748, 5481, 115, 4935, 2164, 804, 4141, 3878, 419, 946, 5478, 858, 5490, 4516, 2425, 2135, 5939, 5409, 1217, 3719, 1666, 2887, 2117, 5226, 854, 5022, 4285, 629, 963, 5226, 6417, 2142, 5573, 5284, 963, 5226, 5929, 373, 2043, 1086, 963, 5226, 3731, 3279, 373, 1851, 963, 5226, 1476, 2284, 854, 1556, 963, 4606, 2811, 3527, 2198, 5420, 1217, 5489, 2887, 1336, 4557, 5095, 3021, 4282, 2339, 4590, 1679, 2117, 4845, 4303, 4250, 2141, 2258, 5748, 1534, 972, 3679, 3634, 4328, 3139, 4228, 2079, 943, 5849, 5303, 4250, 6381, 1223, 2030, 5026, 5734, 1541, 2935, 5343, 1552, 1217, 3634, 3180, 4385, 2144, 4557, 3634, 4328, 3139, 4228, 2079, 943, 5849, 5303, 4250, 1525, 1980, 1271, 4228, 1155, 1217, 4669, 4112, 562, 1317, 1598, 1229, 2852, 788, 4250, 1511, 2043, 2079, 943, 373, 1851, 5734, 3300, 5359, 5554, 4622, 5755, 623, 2425, 2135, 4349, 1217, 3719, 1666, 3932, 2851, 5284, 3780, 5095, 44, 3890, 5234, 6402, 2117, 5031, 5726, 1217, 5095, 5086, 4112, 2128, 2076, 2117, 5031, 4112, 1217, 5095, 93, 5561, 378, 2850, 2117, 5031, 2194, 1217, 249, 6432, 4112, 4557, 44, 3890, 1271, 5734, 373, 538, 1271, 155, 4310, 5620, 854, 2425, 1999, 5194, 5833, 2788, 667, 4941, 3634, 5454, 4771, 2814, 1217, 426, 1999, 6409, 4406, 1255, 5963, 378, 3399, 2128, 4327, 2765, 3004, 5026, 4328, 1217, 3011, 6436, 1336, 4557, 6409, 2258, 3097, 2935, 2814, 6436, 4557, 3634, 4328, 2079, 943, 4250, 3004, 4328, 623, 4327, 3004, 5720, 1032, 2425]}\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_datasets['train'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'input_ids': [2425, 2135, 5939, 5409, 1217, 3719, 1666, 2887, 2117, 5226, 854, 5022, 4285, 629, 963, 5226, 6417, 2142, 5573, 5284, 963, 5226, 5929, 373, 2043, 1086, 963, 5226, 3731, 3279, 373, 1851, 963, 5226, 1476, 2284, 854, 1556, 963, 4606, 2811, 3527, 2198, 5420, 1217, 5489, 2887, 1336, 4557, 5095, 3021, 4282, 2339, 4590, 1679, 2117, 4845, 4303, 4250, 2141, 2258, 5748, 1534, 972, 3679, 3634, 4328, 3139, 4228, 2079, 943, 5849, 5303, 4250, 6381, 1223, 2030, 5026, 5734, 1541, 2935, 5343, 1552, 1217, 3634, 3180, 4385, 2144, 4557, 3634, 4328, 3139, 4228, 2079, 943, 5849, 5303, 4250, 1525, 1980, 1271, 4228, 1155, 1217, 4669, 4112, 562, 1317, 1598, 1229, 2852, 788, 4250, 1511, 2043, 2079, 943, 373, 1851, 5734, 3300, 5359, 5554, 4622, 5755, 623, 2425, 2135], 'labels': [2425, 2135, 5939, 5409, 1217, 3719, 1666, 2887, 2117, 5226, 854, 5022, 4285, 629, 963, 5226, 6417, 2142, 5573, 5284, 963, 5226, 5929, 373, 2043, 1086, 963, 5226, 3731, 3279, 373, 1851, 963, 5226, 1476, 2284, 854, 1556, 963, 4606, 2811, 3527, 2198, 5420, 1217, 5489, 2887, 1336, 4557, 5095, 3021, 4282, 2339, 4590, 1679, 2117, 4845, 4303, 4250, 2141, 2258, 5748, 1534, 972, 3679, 3634, 4328, 3139, 4228, 2079, 943, 5849, 5303, 4250, 6381, 1223, 2030, 5026, 5734, 1541, 2935, 5343, 1552, 1217, 3634, 3180, 4385, 2144, 4557, 3634, 4328, 3139, 4228, 2079, 943, 5849, 5303, 4250, 1525, 1980, 1271, 4228, 1155, 1217, 4669, 4112, 562, 1317, 1598, 1229, 2852, 788, 4250, 1511, 2043, 2079, 943, 373, 1851, 5734, 3300, 5359, 5554, 4622, 5755, 623, 2425, 2135]}\n"
     ]
    }
   ],
   "source": [
    "print(lm_datasets['train'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "image_detection",
   "language": "python",
   "name": "image_detection"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
